<!DOCTYPE html>
<html>

<head>
    <title>Wireframe Test</title>
    <style>
        body {
            margin: 0;
            padding: 20px;
            background: #0a0e1a;
            color: white;
            font-family: sans-serif;
        }

        #status {
            margin: 20px 0;
        }

        .container {
            position: relative;
            width: 640px;
            height: 480px;
            margin: 0 auto;
            border: 2px solid #4dadf7;
        }

        video {
            width: 100%;
            height: 100%;
            transform: scaleX(-1);
        }

        canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            transform: scaleX(-1);
            pointer-events: none;
        }
    </style>
    <script defer src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0/dist/tf.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api@1.7.12/dist/face-api.min.js"></script>
</head>

<body>
    <h1>Wireframe Mesh Test</h1>
    <div id="status">Loading models...</div>
    <button id="startBtn">Start Webcam</button>
    <div class="container">
        <video id="video" autoplay playsinline muted></video>
        <canvas id="canvas"></canvas>
    </div>

    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const status = document.getElementById('status');
        const startBtn = document.getElementById('startBtn');

        let stream = null;
        let detectionInterval = null;

        async function loadModels() {
            try {
                const MODEL_URL = 'https://cdn.jsdelivr.net/npm/@vladmandic/face-api@1.7.12/model';
                await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
                await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
                status.textContent = 'Models loaded! Click "Start Webcam" to begin.';
            } catch (err) {
                status.textContent = 'Error loading models: ' + err.message;
                console.error(err);
            }
        }

        startBtn.addEventListener('click', async () => {
            try {
                stream = await navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 } });
                video.srcObject = stream;

                video.addEventListener('loadedmetadata', () => {
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    startDetection();
                });

                status.textContent = 'Webcam started. Detecting...';
            } catch (err) {
                status.textContent = 'Webcam error: ' + err.message;
            }
        });

        function startDetection() {
            detectionInterval = setInterval(async () => {
                try {
                    const detections = await faceapi
                        .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
                        .withFaceLandmarks();

                    ctx.clearRect(0, 0, canvas.width, canvas.height);

                    if (detections) {
                        const landmarks = detections.landmarks.positions;

                        // Draw simple wireframe
                        ctx.strokeStyle = '#51cf66';
                        ctx.lineWidth = 1.5;
                        ctx.globalAlpha = 0.8;

                        // Draw all landmarks as dots
                        landmarks.forEach(point => {
                            ctx.fillStyle = '#4dadf7';
                            ctx.beginPath();
                            ctx.arc(point.x, point.y, 3, 0, 2 * Math.PI);
                            ctx.fill();
                        });

                        // Draw simple connections
                        const connections = [
                            [0, 16], // Jaw
                            [17, 21], [22, 26], // Eyebrows
                            [27, 30], [31, 35], // Nose
                            [36, 41], [42, 47], // Eyes
                            [48, 59], [60, 67] // Mouth
                        ];

                        connections.forEach(([start, end]) => {
                            ctx.beginPath();
                            ctx.moveTo(landmarks[start].x, landmarks[start].y);
                            ctx.lineTo(landmarks[end].x, landmarks[end].y);
                            ctx.stroke();
                        });

                        status.textContent = `Face detected! ${landmarks.length} landmarks found.`;
                    } else {
                        status.textContent = 'No face detected. Move closer to camera.';
                    }
                } catch (err) {
                    console.error('Detection error:', err);
                }
            }, 100);
        }

        window.addEventListener('DOMContentLoaded', loadModels);
    </script>
</body>

</html>